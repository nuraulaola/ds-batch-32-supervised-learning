{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnBN0Y_-Ye94"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX5YaXTUYe99"
      },
      "source": [
        "Consider [this](https://www.kaggle.com/c/titanic) scenario:\n",
        "\n",
        "> The sinking of the Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew. While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
        "\n",
        "We could use the classification method to analyze it.\n",
        "\n",
        "In this session, we want to compare the kNN, decision tree, and random forest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgUUWfWfYe-A"
      },
      "source": [
        "## Prepare and explore the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mposIL5fY9RT"
      },
      "outputs": [],
      "source": [
        "# Package imports\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVUoySyTZEYo"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zU7QzZ2Ye-E"
      },
      "source": [
        "Since the PassengerId and Name is just our data identification, we could PassengerId column as a rownames while the Name column could be dropped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8S4_PyNYe-G"
      },
      "outputs": [],
      "source": [
        "df = df.set_index('PassengerId') \\\n",
        "    .drop('Name', axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GOTO3M2Ye-H"
      },
      "source": [
        "Lets do some data exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BURvaHpqYe-I"
      },
      "outputs": [],
      "source": [
        "# Information about datatype\n",
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwMig0gFYe-J"
      },
      "source": [
        "The data contains 891 rows and 11 columns, each row represents a customer. The columns are:\n",
        "* `Survived` - Is the passenger survived (0 = No, 1 = Yes)\n",
        "* `Pclass` - The passenger's ticket class (1 = 1st, 2 = 2nd, 3 = 3rd)\n",
        "* `Sex` - The customer's sex (male/female)\n",
        "* `Age` - The customer's age in year\n",
        "* `SibSp` - Number of siblings/spouse aboard the Titanic\n",
        "* `Parch` - Number of parents/children aboard the Titanic\n",
        "* `Ticket` - The customer's ticket number\n",
        "* `Fare` - The customer's ticket number\n",
        "* `Cabin` - The customer's cabin number\n",
        "* `Embarked` - The customer's embarkation port (C = Cherbourg, Q = Queenstown, S = Southampton)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dKQTsKuYe-J"
      },
      "outputs": [],
      "source": [
        "df.groupby(['Survived']).size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCEUI9EBZgwi"
      },
      "outputs": [],
      "source": [
        "# Check missing value\n",
        "\n",
        "df.isnull().sum() # / len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXXXAmLAaRhB"
      },
      "outputs": [],
      "source": [
        "df[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M2s6I1ua84b"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8A4iwq9Ye-L"
      },
      "source": [
        "Before running the models, we have to preprocess the data to make sure that our model could use the data as an input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8S6kkDVYe-L"
      },
      "outputs": [],
      "source": [
        "# Drop some unnecessary columns\n",
        "\n",
        "df = df.drop(['Ticket', 'Cabin', 'Embarked'], axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EyxPEP1Ye-L"
      },
      "source": [
        "We found out that the Ticket column is just and identifier so we could remove it. The Cabin column has a very large number of missing values. Besides, the Pclass and Fare columns should be enough to infer the passenger's status and position in the Titanic so we could the Cabin column. We could also dropped the Embarked column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95XK6rM3acj5"
      },
      "outputs": [],
      "source": [
        "# Handle the missing value\n",
        "\n",
        "df.loc[df['Age'].isnull(), 'Age'] = df['Age'].median()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOYvGeL2Ye-M"
      },
      "source": [
        "We could fill the missing value of the Age column using its median."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3ZDAoQ-bUKX"
      },
      "outputs": [],
      "source": [
        "# Recode the non numeric variable\n",
        "\n",
        "# pd.get_dummies(df, columns=['Sex'])\n",
        "\n",
        "df = pd.get_dummies(df, columns=['Sex'], drop_first=True)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr2Aa-utYe-M"
      },
      "source": [
        "Since our model could just accept the numeric value, we have to recode the non numeric column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kwyw-dtb_Dq"
      },
      "outputs": [],
      "source": [
        "# Assign the data to new variable\n",
        "\n",
        "X = df[['Pclass', 'Age', 'SibSp', 'Parch', 'Sex_male', 'Fare']]\n",
        "y = df['Survived']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-c1USyscxGJ"
      },
      "source": [
        "## Data preprocessing 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEYDv0hZc24y"
      },
      "outputs": [],
      "source": [
        "# Split the data\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee5jnwMQYe-N"
      },
      "source": [
        "The train data could be used as an input of our model while the test data could be used to measure our model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGnXzMIrYe-N"
      },
      "outputs": [],
      "source": [
        "# Scale the data\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train) # Fit the data then do transform\n",
        "X_test = scaler.transform(X_test) # Do the transform using fitted data\n",
        "\n",
        "X_train = pd.DataFrame(X_train, columns=X.columns)\n",
        "X_test = pd.DataFrame(X_test, columns=X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjSSAf72dsiL"
      },
      "outputs": [],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QuLEFXoYe-N"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3GQP18Xd630"
      },
      "outputs": [],
      "source": [
        "# Create function to evaluate our model\n",
        "def classification_eval (aktual, prediksi, name):\n",
        "    cm = confusion_matrix(aktual, prediksi)\n",
        "    tp = cm[1][1]\n",
        "    tn = cm[0][0]\n",
        "    fp = cm[0][1]\n",
        "    fn = cm[1][0]\n",
        "\n",
        "    accuracy = round((tp+tn) / (tp+tn+fp+fn) * 100, 2)\n",
        "    precision = round((tp) / (tp+fp) * 100, 2)\n",
        "    recall = round((tp) / (tp+fn) * 100, 2)\n",
        "    specificity = round((tn) / (tn+fp) * 100, 2)\n",
        "\n",
        "    print('Evaluation Model:', name)\n",
        "    print(cm)\n",
        "    print('Accuracy   :', accuracy, '%')\n",
        "    print('Precision  :', precision, '%')\n",
        "    print('Recall     :', recall, '%')\n",
        "    print('Specificity:', specificity, '%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6JelhoEYe-N"
      },
      "source": [
        "### kNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LVhB8GTeNEN"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgVhrgc2ffTx"
      },
      "outputs": [],
      "source": [
        "y_train_pred = knn.predict(X_train)\n",
        "y_test_pred = knn.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeKsu1iPYe-O"
      },
      "outputs": [],
      "source": [
        "y_train_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nt1HjxjgEWD"
      },
      "outputs": [],
      "source": [
        "# Training Performance\n",
        "classification_eval(y_train, y_train_pred, 'KNN Training Perf.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLZ8g0Uaga7t"
      },
      "outputs": [],
      "source": [
        "# Testing Performance\n",
        "classification_eval(y_test, y_test_pred, 'KNN Testing Perf.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loVVOHrYYe-O"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POnM6mzMhu2U"
      },
      "outputs": [],
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQqs5i9ziVr-"
      },
      "outputs": [],
      "source": [
        "y_train_pred = dt.predict(X_train)\n",
        "y_test_pred = dt.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ra3jhI03iYbl"
      },
      "outputs": [],
      "source": [
        "# Training Performance\n",
        "classification_eval(y_train, y_train_pred, 'Dectree Training Perf.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jjbd48g0ia-t"
      },
      "outputs": [],
      "source": [
        "# Testing Performance\n",
        "classification_eval(y_test, y_test_pred, 'Dectree Testing Perf.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RD2o95MvYe-U"
      },
      "outputs": [],
      "source": [
        "# Plot Tree\n",
        "fig = plt.figure(figsize=(15, 10))\n",
        "_ = plot_tree(dt, feature_names = X_train.columns, class_names = ['No', 'Yes'])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-4D00AWYe-U"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(list(zip(X_train.columns, dt.feature_importances_)),\n",
        "             columns = ['Feature', 'Importance']) \\\n",
        "    .sort_values('Importance', ascending = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ud8Vg1mJYe-U"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1-q83Mig4j9"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(random_state = 123)\n",
        "rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihOgbXHtheud"
      },
      "outputs": [],
      "source": [
        "y_train_pred = rf.predict(X_train)\n",
        "y_test_pred = rf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3j3_fWbhmKc"
      },
      "outputs": [],
      "source": [
        "# Training Performance\n",
        "classification_eval(y_train, y_train_pred, 'Ranfor Training Perf.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ul2-88Klho79"
      },
      "outputs": [],
      "source": [
        "# Testing Performance\n",
        "classification_eval(y_test, y_test_pred, 'Ranfor Testing Perf.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIK2ecEMYe-V"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(list(zip(X_train.columns, rf.feature_importances_)),\n",
        "             columns = ['Feature', 'Importance']) \\\n",
        "    .sort_values('Importance', ascending = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8u92UJYYe-V"
      },
      "outputs": [],
      "source": [
        "# Individual tree\n",
        "rf.estimators_"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}